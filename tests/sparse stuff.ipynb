{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f8dbc5-6f53-42ff-b217-a4facc8cd54f",
   "metadata": {},
   "source": [
    "# Tests on how I handle sparsity. will move into a unit test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a935fcb5-b455-45f6-8a11-6e70d42b1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import itertools as it\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from time import perf_counter\n",
    "def append_path(s):\n",
    "    if s in sys.path:\n",
    "        return\n",
    "    sys.path.append(s)\n",
    "    \n",
    "#You don’t need those lines if you installed the packages\n",
    "append_path(\"/home/tristan/research/ot_markov_distances/\")\n",
    "append_path(\"/home/tristan/research/ot_markov_distances/experiments\")\n",
    "append_path(\"/home/tristan/research/tb_ml/\")\n",
    "append_path(\"/home/tristan/research/FGW/lib\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cdd8899-1adf-45b1-bfb1-9e9b5d4ad820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed1ce4c-aa6c-4156-81d4-5e7b0b6c3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_lib.misc import all_equal\n",
    "from ot_markov_distances import wl_reg_infty, sinkhorn\n",
    "from ot_markov_distances.utils import weighted_transition_matrix, draw_markov, densify\n",
    "\n",
    "from utils.modules import ParametricMarkovMatrixWithMatchings\n",
    "from utils.data_generation import circle_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a6beff-e279-4b31-9631-bfa2e7578f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare fake test data\n",
    "batch_size = 2\n",
    "n1, n2 = 17, 23\n",
    "test_sizes=[n1] * batch_size\n",
    "test_graphs = [circle_graph(size, kind=\"nn\", k=2) for size in test_sizes]\n",
    "test_matrices = [weighted_transition_matrix(g, q=.1) for g in test_graphs]\n",
    "mx = torch.stack(test_matrices)\n",
    "test_sizes=[n2] * batch_size\n",
    "test_graphs = [circle_graph(size, kind=\"nn\", k=3) for size in test_sizes]\n",
    "test_matrices = [weighted_transition_matrix(g, q=.1) for g in test_graphs]\n",
    "my = torch.stack(test_matrices)\n",
    "\n",
    "\n",
    "C = torch.rand((batch_size, n1, n2)) * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482ac3c-5fe8-4ad7-a056-753427d5b2d3",
   "metadata": {},
   "source": [
    "## stuff on MX"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7b1a2ce-d904-499b-bd86-92f3ac0b6574",
   "metadata": {},
   "source": [
    "# useful variables\n",
    "*batch, n, n_ = mx.shape\n",
    "assert all_equal(n, n_)\n",
    "\n",
    "# flat stuff\n",
    "mx_flat = mx.view(-1, n1)\n",
    "my_flat= my.view(-1, n2)\n",
    "n_flat, _ = mx_flat.shape #n_flat = n * batch\n",
    "mx_flat.shape, my_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aab0e6f-a5a6-45ba-b1b0-e03d87d5238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max degree\n",
    "mx_flat_degree = (mx_flat>0).sum(-1)\n",
    "mx_max_degree = mx_flat_degree.max()\n",
    "mx_max_degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca97e52f-9e97-4087-8ecd-c0dddaf2ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices and padding masks\n",
    "nonzero_indices = torch.zeros((*batch, n, mx_max_degree), dtype=torch.long)\n",
    "nonzero_indices_mask = torch.zeros((*batch, n, mx_max_degree), dtype=bool)\n",
    "nzi_flat = nonzero_indices.view(-1, mx_max_degree)\n",
    "nzi_flat_mask = nonzero_indices_mask.view(-1, mx_max_degree)\n",
    "\n",
    "for i in range(n_flat):\n",
    "    line, = mx_flat[i].nonzero(as_tuple=True)\n",
    "    line_len = len(line)\n",
    "    nzi_flat[i, :line_len] = line\n",
    "    nzi_flat_mask[i, :line_len] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cfb3b0-a8d6-4cb7-9af9-01fd7c15a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#densified\n",
    "# we want mx_dense[*b, i, k] = mx[*b, i, nonzero_indices[*b, i, k]] if nonzero_indices_mask[*b, i, k] else 0\n",
    "mx_dense = torch.empty((*batch, n, mx_max_degree))\n",
    "mx_dense_flat = mx_dense.view((-1, mx_max_degree))\n",
    "mx_dense_flat[...] = torch.where(nzi_flat_mask, mx_flat.gather(1, nzi_flat), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a88a681-704c-4497-80cb-0529dece83d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.3000, 0.3000, 0.3000, 0.0000],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.1000, 0.3000, 0.0000],\n",
       "        [0.1000, 0.3000, 0.3000, 0.3000, 0.0000],\n",
       "        [0.1000, 0.4500, 0.4500, 0.0000, 0.0000],\n",
       "        [0.1000, 0.4500, 0.4500, 0.0000, 0.0000],\n",
       "        [0.2250, 0.1000, 0.2250, 0.2250, 0.2250],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.2250, 0.2250, 0.1000, 0.2250, 0.2250],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.3000, 0.1000, 0.3000, 0.3000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.1000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.1000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.1000, 0.0000],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.1000, 0.0000],\n",
       "        [0.1000, 0.2250, 0.2250, 0.2250, 0.2250],\n",
       "        [0.1000, 0.4500, 0.4500, 0.0000, 0.0000],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.1000, 0.4500, 0.4500, 0.0000, 0.0000],\n",
       "        [0.1000, 0.4500, 0.4500, 0.0000, 0.0000],\n",
       "        [0.1000, 0.3000, 0.3000, 0.3000, 0.0000],\n",
       "        [0.3000, 0.1000, 0.3000, 0.3000, 0.0000],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.1000, 0.3000, 0.0000],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.1000, 0.4500, 0.4500, 0.0000, 0.0000],\n",
       "        [0.2250, 0.2250, 0.2250, 0.2250, 0.1000],\n",
       "        [0.4500, 0.1000, 0.4500, 0.0000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.1000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.1000, 0.0000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.1000, 0.0000],\n",
       "        [0.4500, 0.4500, 0.1000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_dense_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "907a2dd0-4389-4622-8d9f-e2067601abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_index2, mx_mask2, mx_dense2 =  densify(mx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2f016-283f-4370-b237-eb179754bbc7",
   "metadata": {},
   "source": [
    " ### Unit tests !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8edbbf06-cd16-4dbb-a65d-63198e1e80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (mx_index2 ==  nonzero_indices).all()\n",
    "assert (mx_mask2 == nonzero_indices_mask).all()\n",
    "\n",
    "assert torch.allclose(mx_dense.sum(-1), torch.tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40abe906-bbc2-46e5-bafc-b6bb5b22c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b, i, j in it.product(*(range(i) for i in (*batch, n, mx_max_degree))):\n",
    "    assert mx_dense2[b, i, j] == mx[b, i, mx_index2[b, i, j]] or not mx_mask2[b, i, j].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f22c5620-2ed9-42a1-8b62-72f3507f6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b, i, j in it.product(*(range(i) for i in (*batch, n, n))):\n",
    "    assert (mx[b, i, j].item() == 0) == (\n",
    "        j not in mx_index2[b, i]\n",
    "        or not mx_mask2[b, i, list(mx_index2[b, i]).index(j)]\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8094b99-9980-4de7-8a83-237d027ab306",
   "metadata": {},
   "source": [
    "## Stuff on C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d68985-c9f6-4be4-b6d1-ab65efcc9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.rand((batch_size, n1, n2)) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7359d6c2-d889-414b-87a3-7f4f7bef836d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 23])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_index, mx_mask, mx_dense =  densify(mx)\n",
    "my_index, my_mask, my_dense =  densify(my)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d22875-d7da-4179-99f6-fabf9ba94c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f8c7661-536d-47ea-bc64-8c4afb2c6a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 23, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b22a77c0-0d66-4246-b29f-af30472c9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we’re assuming all this has already been broadcast to each other, so batches should be the same \n",
    "b, n, m = C.shape\n",
    "b_, n_, dx = mx_index.shape\n",
    "b__, m_, dy = my_index.shape\n",
    "assert all_equal(b, b_, b__) and n == n_ and m == m_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "471b894e-42fe-486b-bb7c-ab0cdca88095",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = C.contiguous()\n",
    "\n",
    "C_index =  m * mx_index[:, :, None, :, None] +  my_index[:, None, :, None, :]\n",
    "# b, n, m, dx, dy\n",
    "C_index = C_index.reshape(b, n, m, dx*dy)\n",
    "C_dense = C.view(b, n * m)[:, None, None, :]\\\n",
    "    .broadcast_to(b, n, m, n*m)\\\n",
    "    .gather(-1, C_index)\\\n",
    "    .reshape(b, n, m, dx, dy)\n",
    "# believe me it works\n",
    "# god I hate indices\n",
    "\n",
    "for bi, ni, mi, i1, i2 in it.product(range(b), range(n), range(m), range(dx), range(dy)):\n",
    "    #print(bi, ni, mi, i1, i2)\n",
    "    assert C_dense[bi, ni, mi, i1, i2] == C[bi, mx_index[bi, ni, i1], my_index[bi, mi, i2]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "327fd2e0-a97c-4a59-8ca6-43c406308ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, b * C.stride(0), step=C.stride(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f014aeb6-8d94-4743-9eaa-6221d568483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_index2 = C.stride(1) * mx_index[:, :, None, :, None] +  my_index[:, None, :, None, :] + torch.arange(0, b * C.stride(0), step=C.stride(0))[:, None, None, None, None]\n",
    "C_index2.shape\n",
    "\n",
    "(C.view(-1)[C_index2] == C_dense).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d826eafc-8405-412f-8644-f6a7fd3df87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_mask = (mx_mask[:, :, None, :, None] & my_mask[:, None, :, None, :])\n",
    "C_dense[C_mask == False] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93ae8b03-d331-4d09-b96a-b378f519eb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(sinkhorn(mx_dense[:, :, None, :], my_dense[:, None, :, :], C_dense, epsilon=.1 ) , sinkhorn(mx[:, :, None, :], my[:, None, :, :], C[:, None, None, :, :], epsilon=.1), atol=1e-4, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deb44f1d-0502-40b3-9d45-adb798d795eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.73 s ± 83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sinkhorn(mx_dense[:, :, None, :], my_dense[:, None, :, :], C_dense, epsilon=.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e292ae85-9a3d-47ab-82e5-1bfdfb21a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.6 s ± 4.41 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "sinkhorn(mx[:, :, None, :], my[:, None, :, :], C[:, None, None, :, :], epsilon=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075d1fe-b8b8-4a94-92fd-96ec8563e5e9",
   "metadata": {},
   "source": [
    "That’s nice, isn’t it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e57420b-d467-4688-8df3-8cd714c66f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "# this may be slightly more general, but it requires non contiguous reshaping, so we end up having to copy C.\n",
    "# which kills the purpose\n",
    "\n",
    "mx_index, mx_mask, mx_dense =  densify(mx)\n",
    "my_index, my_mask, my_dense =  densify(my)\n",
    "# we’re assuming all this has already been broadcast to each other, so batches should be the same \n",
    "mx_index = mx_index[:, :, None, :]\n",
    "my_index = my_index[:, None, :, :]\n",
    "mx_mask = mx_mask[:, :, None, :]\n",
    "my_mask = my_mask[:, None, :, :]\n",
    "\n",
    "C = C[:, None, None, :, :]\n",
    "# we’re assuming all this has already been broadcast to each other, so batches should be the same \n",
    "*batch1, dx = mx_index.shape\n",
    "*batch2, dy = my_index.shape\n",
    "*batch3, n, m = C.shape\n",
    "batch = torch.broadcast_shapes(batch1, batch2, batch3)\n",
    "\n",
    "mx_index_flat = mx_index.expand(*batch, dx).reshape(-1, dx)\n",
    "my_index_flat = my_index.expand(*batch, dy).reshape(-1, dy)\n",
    "mx_mask_flat = mx_mask.expand(*batch, dx).reshape(-1, dx)\n",
    "my_mask_flat = my_mask.expand(*batch, dy).reshape(-1, dy)\n",
    "C_flat = C.expand(*batch, n, m).view(-1, n, m)\n",
    "\n",
    "C_index_flat = m * mx_index_flat +  my_index_flat\n",
    "C_dense_flat = C_flat.gather(-1, C_index_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ecd6f06-6a2e-4d09-bf69-178fd690a91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting stuff back\n",
    "mx_test = torch.zeros_like(mx)\n",
    "mx_test.scatter_add_(-1, mx_index, mx_dense)\n",
    "(mx_test == mx).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1822ac17-718e-4e83-a9aa-93dc5b388d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc640f20-2ccd-4ebb-b7f6-c25ca546b0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 23, 5, 7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_index2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c76e31bd-40dd-49e3-9e4b-edccac50a6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 23, 5, 7])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08bf9c39-b45f-496f-b26c-fc7facb5a8d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index_add_(): Indexing dim 2 is out of bounds of the source tensor with dim 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m C2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n, m, b, n, m)\u001b[38;5;241m.\u001b[39mview(n, m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mC2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_index2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_dense\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index_add_(): Indexing dim 2 is out of bounds of the source tensor with dim 1"
     ]
    }
   ],
   "source": [
    "C2 = torch.zeros(n, m, b, n, m).view(n, m, -1)\n",
    "C2.index_add_(-1, C_index2.view(-1), C_dense.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02013ad3-8946-433f-ba34-25e19d8533f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 23, 782])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d26a72a4-568a-4e34-b1ab-c817e7704892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_project_C(C_dense, C_index, C_mask=None):\n",
    "    b, n, m, dx, dy = C_dense.shape\n",
    "    if C_mask is not None:\n",
    "        C_dense = C_dense.clone()\n",
    "        C_dense[C_mask==0]=0\n",
    "    C_dense = torch.einsum(\"bijxy->ijbxy\", C_dense)\n",
    "    C_index = torch.einsum(\"bijxy->ijbxy\", C_index)\n",
    "    C = torch.zeros(n, m, b, n, m).view(n, m, -1) \n",
    "    C.scatter_add_(-1, C_index.reshape(n, m, -1), C_dense.reshape(n, m, -1))\n",
    "    return torch.einsum(\"ijbxy->bijxy\", C.view(n, m, b, n, m))\n",
    "rpC = re_project_C(C_dense, C_index2, C_mask)\n",
    "assert ((rpC == 0) | (rpC == C[:, None, None, ...])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e7e76-6f91-423b-8a41-38755631072f",
   "metadata": {},
   "source": [
    "## Incorporate it into discounted WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8d4faf38-008e-40ed-a561-d33d89aed4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ot_markov_distances.utils import densify, cost_matrix_index, reindex_cost_matrix\n",
    "from ot_markov_distances.discounted_wl import DiscountedWlCostMatrix, double_last_dimension\n",
    "from ot_markov_distances.sinkhorn import sinkhorn_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c4ff1fc8-b73f-4522-88f6-807cddd4be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_lib.misc import all_equal, debug_time\n",
    "from ml_lib.pipeline.annealing_scheduler import get_scheduler\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b761035f-e1f3-4431-aea8-6b59db9d3ba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDiscountedWlCostMatrixSparse\u001b[39;00m(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mFunction):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, MX: Tensor, MY: Tensor, \n\u001b[1;32m      5\u001b[0m         distance_matrix: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m         sinkhorn_iter_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m         ):\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124;03m\"\"\"computes the regularized WL distance\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m        computes the regularized WL distance between two markov transition matrices \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m            sinkhorn_iter: number of sinkhorn iterations for a step\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class DiscountedWlCostMatrixSparse(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, MX: Tensor, MY: Tensor, \n",
    "        distance_matrix: Tensor,\n",
    "        delta: float = .4,\n",
    "        sinkhorn_reg: float=.01,\n",
    "        max_iter: int = 50,\n",
    "        convergence_threshold_rtol = 5e-3,\n",
    "        convergence_threshold_atol = 1e-6,\n",
    "        sinkhorn_iter: int= 100,\n",
    "        return_differences: bool=False,\n",
    "        sinkhorn_iter_scheduler=\"constant\"\n",
    "        ):\n",
    "        \"\"\"computes the regularized WL distance\n",
    "\n",
    "        computes the regularized WL distance between two markov transition matrices \n",
    "        (represented as torch tensor)\n",
    "\n",
    "        Batched over first dimension (b)\n",
    "        \n",
    "        delta can be a torch tensor (or a simple float). \n",
    "        please don’t modify it inplace between forward and backward, I don't check for that\n",
    "\n",
    "        Args:\n",
    "            MX: (b, n, n) first transition tensor\n",
    "            MY: (b, m, m) second transition tensor\n",
    "            l1: (b, n,) label values for the first space\n",
    "            l2: (b, m,) label values for the second space\n",
    "            k: number of steps (k parameter for the WL distance)\n",
    "            muX: stationary distribution for MX (if omitted, will be recomuputed)\n",
    "            muY: stationary distribution for MY (if omitted, will be recomuputed)\n",
    "            reg: regularization parameter for sinkhorn\n",
    "            delta: regularization parameter for WL\n",
    "            sinkhorn_iter: number of sinkhorn iterations for a step\n",
    "        \"\"\"\n",
    "        b, n, n_ = MX.shape\n",
    "        b_, m, m_ = MY.shape\n",
    "        b__, n__, m__  = distance_matrix.shape\n",
    "        assert all_equal(n, n_, n__) and all_equal(m, m_, m__) and all_equal(b, b_, b__)\n",
    "        assert max_iter >= 1, \"Can’t really converge without iterating\"\n",
    "        one_minus_delta = 1 - delta\n",
    "        scheduler = get_scheduler(sinkhorn_iter_scheduler, T_0=max_iter, beta_0=sinkhorn_iter)\n",
    "        \n",
    "        differences = []\n",
    "        debug_time()\n",
    "        with torch.no_grad():\n",
    "            cost_matrix = delta * distance_matrix\n",
    "            cost_matrix = cost_matrix.contiguous()\n",
    "            mx_index, mx_mask, mx_dense = densify(MX)\n",
    "            my_index, my_mask, my_dense = densify(MY)\n",
    "            mx_dense = mx_dense[:, :, None, :] # b, n, 1, dx\n",
    "            my_dense = my_dense[:, None, :, :] # b, 1, m, dy\n",
    "            c_index, c_mask = cost_matrix_index(C, mx_index, my_index, mx_mask, my_mask)\n",
    "\n",
    "            for _ in range(max_iter):\n",
    "                # sinkhorn pass\n",
    "                f, g, log_P = sinkhorn_internal(\n",
    "                        mx_dense, # b, n, 1, dx\n",
    "                        my_dense, # b, 1, m, dy\n",
    "                        reindex_cost_matrix(C, c_index, c_mask), # b, n, m, dx, dy\n",
    "                        epsilon=sinkhorn_reg, \n",
    "                        k= int(scheduler.step()) + 1\n",
    "                )# f : (b, n, m, dx) , g:(b, n, m, dy), log_P:(b, n, m, dx, dy)\n",
    "                sinkhorn_result = (f * mx_dense).sum(-1) + (g*my_dense).sum(-1)\n",
    "                # update\n",
    "                new_cost_matrix = delta * distance_matrix \\\n",
    "                    + one_minus_delta * sinkhorn_result # b, n, m\n",
    "                new_cost_matrix = new_cost_matrix.contiguous()\n",
    "                \n",
    "                # stop condition \n",
    "                if torch.allclose(cost_matrix, new_cost_matrix, \n",
    "                            rtol=convergence_threshold_rtol,\n",
    "                            atol=convergence_threshold_atol):\n",
    "                    break\n",
    "                differences.append(F.mse_loss(cost_matrix, new_cost_matrix))\n",
    "                cost_matrix = new_cost_matrix \n",
    "                debug_time(\"iteration\")\n",
    "            else:\n",
    "                warnings.warn(\"regularized WL did not converge\")\n",
    "\n",
    "        ctx.save_for_backward(f, g, log_P, mx_index, my_index, mx_mask, my_mask, c_index, c_mask) #type:ignore\n",
    "        ctx.delta = delta\n",
    "        ctx.one_minus_delta = one_minus_delta\n",
    "        if return_differences:\n",
    "            return cost_matrix, differences\n",
    "        return cost_matrix\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        See the paper for details on how the backward pass is computed.\n",
    "        \n",
    "        Args:\n",
    "            grad_output: (b,)\n",
    "        \"\"\"\n",
    "        f_dense, g_dense, log_P_dense, mx_index, my_index, mx_mask, my_mask, c_index, c_mask = ctx.saved_tensors\n",
    "        b, n, m, dx, dy = log_P_dense.shape\n",
    "        delta = ctx.delta\n",
    "        one_minus_delta = ctx.one_minus_delta\n",
    "        device = log_P_dense.device\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #restore f, g, log_P to the right size            \n",
    "            f = torch.zeros((b, n, m, n))\\\n",
    "                .scatter_add_(-1, mx_index[:, :, None, :].broadcast_to(b, n, m, dx), f_dense)\n",
    "            g = torch.zeros((b, n, m, m))\\\n",
    "                .scatter_add_(-1, my_index[:, None, :, :].broadcast_to(b, n, m, dy), g_dense)\n",
    "            #P_dense[c_mask == 0] = 0 # I dont think i actually want that. \n",
    "            P_dense= log_P_dense.exp()\n",
    "            P = re_project_C(P_dense, c_index)    \n",
    "            #P = log_P.exp() #b, n, m, n, m\n",
    "            # f  (b, n, m, n)\n",
    "            # F = torch.einsum(\"bijl->bijil\", f) #doesnt work but that’s the idea\n",
    "            F = torch.permute(f, (0, 2, 3, 1)) #bijl -> bjli\n",
    "            F = double_last_dimension(F) #bjlii\n",
    "            F = torch.permute(F, (0, 3, 1, 4, 2)) #bijil\n",
    "            # (n, m, n, n)\n",
    "            # g (b, n, m, m)\n",
    "            # G = torch.einsum(\"bijl->bijjl\", g) #(n, m, m, m)\n",
    "            G = torch.permute(g, (0, 1, 3, 2)) #bijl -> bilj\n",
    "            G = double_last_dimension(G) #biljj\n",
    "            G = torch.permute(G, (0, 1, 3, 4, 2)) #bijjl \n",
    "        \n",
    "            mymatrix = torch.eye(n*m, device=device)[None, ...] - one_minus_delta * P.reshape(b, n*m, n*m) \n",
    "            # b, n*m, n*m\n",
    "            \n",
    "            #print(torch.det(mymatrix))\n",
    "            #print(mymatrix)\n",
    "            #see paper for a proof this is diagonally dominant, thus invertible\n",
    "            Delta = delta * torch.inverse(mymatrix)\n",
    "            Gamma = one_minus_delta * torch.linalg.solve(mymatrix, F.reshape(b, n*m, n*n))\n",
    "            Theta = one_minus_delta * torch.linalg.solve(mymatrix, G.reshape(b, n*m, m*m))\n",
    "            \n",
    "            Delta = Delta.reshape(b, n, m, n, m)\n",
    "            Gamma = Gamma.reshape(b, n, m, n, n) \n",
    "            Theta = Theta.reshape(b, n, m, m, m)\n",
    "\n",
    "            d_cost_matrix = torch.einsum(\"bijkl,bij->bkl\", Delta, grad_output)\n",
    "            d_mx = torch.einsum(\"bijkl,bij->bkl\", Gamma, grad_output)\n",
    "            d_my = torch.einsum(\"bijkl,bij->bkl\", Theta, grad_output)\n",
    "                        \n",
    "            d_mx = d_mx - d_mx.mean(-1, keepdims=True)# normalize the markov gradients to stay in the markov space\n",
    "            d_my = d_my - d_my.mean(-1, keepdims=True)        \n",
    "        return (d_mx, d_my, d_cost_matrix, *[None]*8 )\n",
    "\n",
    "mx = mx.detach().requires_grad_()\n",
    "my = my.detach().requires_grad_()\n",
    "C = C.detach().requires_grad_()\n",
    "\n",
    "C_infty = DiscountedWlCostMatrixSparse.apply(mx, my, C)\n",
    "C_infty.sum().backward()\n",
    "\n",
    "mx_new_grad = mx.grad.detach().clone()\n",
    "my_new_grad = my.grad.detach().clone()\n",
    "C_new_grad = C.grad.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c055b6-43dd-4b4c-bde4-1e73a1f7dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscountedWlCostMatrixSparse(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, MX: Tensor, MY: Tensor, \n",
    "        distance_matrix: Tensor,\n",
    "        delta: float = .4,\n",
    "        sinkhorn_reg: float=.01,\n",
    "        max_iter: int = 50,\n",
    "        convergence_threshold_rtol = 5e-3,\n",
    "        convergence_threshold_atol = 1e-6,\n",
    "        sinkhorn_iter: int= 100,\n",
    "        return_differences: bool=False,\n",
    "        sinkhorn_iter_scheduler=\"constant\"\n",
    "        ):\n",
    "        \"\"\"computes the regularized WL distance\n",
    "\n",
    "        computes the regularized WL distance between two markov transition matrices \n",
    "        (represented as torch tensor)\n",
    "\n",
    "        Batched over first dimension (b)\n",
    "        \n",
    "        delta can be a torch tensor (or a simple float). \n",
    "        please don’t modify it inplace between forward and backward, I don't check for that\n",
    "\n",
    "        Args:\n",
    "            MX: (b, n, n) first transition tensor\n",
    "            MY: (b, m, m) second transition tensor\n",
    "            l1: (b, n,) label values for the first space\n",
    "            l2: (b, m,) label values for the second space\n",
    "            k: number of steps (k parameter for the WL distance)\n",
    "            muX: stationary distribution for MX (if omitted, will be recomuputed)\n",
    "            muY: stationary distribution for MY (if omitted, will be recomuputed)\n",
    "            reg: regularization parameter for sinkhorn\n",
    "            delta: regularization parameter for WL\n",
    "            sinkhorn_iter: number of sinkhorn iterations for a step\n",
    "        \"\"\"\n",
    "        b, n, n_ = MX.shape\n",
    "        b_, m, m_ = MY.shape\n",
    "        b__, n__, m__  = distance_matrix.shape\n",
    "        assert all_equal(n, n_, n__) and all_equal(m, m_, m__) and all_equal(b, b_, b__)\n",
    "        assert max_iter >= 1, \"Can’t really converge without iterating\"\n",
    "        one_minus_delta = 1 - delta\n",
    "        scheduler = get_scheduler(sinkhorn_iter_scheduler, T_0=max_iter, beta_0=sinkhorn_iter)\n",
    "        \n",
    "        differences = []\n",
    "        debug_time()\n",
    "        with torch.no_grad():\n",
    "            cost_matrix = delta * distance_matrix\n",
    "            cost_matrix = cost_matrix.contiguous()\n",
    "            mx_index, mx_mask, mx_dense = densify(MX)\n",
    "            my_index, my_mask, my_dense = densify(MY)\n",
    "            mx_dense = mx_dense[:, :, None, :] # b, n, 1, dx\n",
    "            my_dense = my_dense[:, None, :, :] # b, 1, m, dy\n",
    "            c_index, c_mask = cost_matrix_index(C, mx_index, my_index, mx_mask, my_mask)\n",
    "\n",
    "            for _ in range(max_iter):\n",
    "                # sinkhorn pass\n",
    "                sinkhorn_result = sinkhorn(\n",
    "                        mx_dense, # b, n, 1, dx\n",
    "                        my_dense, # b, 1, m, dy\n",
    "                        reindex_cost_matrix(C, c_index, c_mask), # b, n, m, dx, dy\n",
    "                        epsilon=sinkhorn_reg, \n",
    "                        k= int(scheduler.step()) + 1\n",
    "                )\n",
    "                # update\n",
    "                new_cost_matrix = delta * distance_matrix \\\n",
    "                    + one_minus_delta * sinkhorn_result # b, n, m\n",
    "                new_cost_matrix = new_cost_matrix.contiguous()\n",
    "                \n",
    "                # stop condition \n",
    "                if torch.allclose(cost_matrix, new_cost_matrix, \n",
    "                            rtol=convergence_threshold_rtol,\n",
    "                            atol=convergence_threshold_atol):\n",
    "                    break\n",
    "                differences.append(F.mse_loss(cost_matrix, new_cost_matrix))\n",
    "                cost_matrix = new_cost_matrix\n",
    "                debug_time(\"iteration\")\n",
    "            else:\n",
    "                warnings.warn(\"regularized WL did not converge\")\n",
    "\n",
    "        ctx.save_for_backward(f, g, log_P, mx_index, my_index, mx_mask, my_mask, c_index, c_mask) #type:ignore\n",
    "        ctx.delta = delta\n",
    "        ctx.one_minus_delta = one_minus_delta\n",
    "        if return_differences:\n",
    "            return cost_matrix, differences\n",
    "        return cost_matrix\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        See the paper for details on how the backward pass is computed.\n",
    "        \n",
    "        Args:\n",
    "            grad_output: (b,)\n",
    "        \"\"\"\n",
    "        f_dense, g_dense, log_P_dense, mx_index, my_index, mx_mask, my_mask, c_index, c_mask = ctx.saved_tensors\n",
    "        b, n, m, dx, dy = log_P_dense.shape\n",
    "        delta = ctx.delta\n",
    "        one_minus_delta = ctx.one_minus_delta\n",
    "        device = log_P_dense.device\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #restore f, g, log_P to the right size            \n",
    "            f = torch.zeros((b, n, m, n))\\\n",
    "                .scatter_add_(-1, mx_index[:, :, None, :].broadcast_to(b, n, m, dx), f_dense)\n",
    "            g = torch.zeros((b, n, m, m))\\\n",
    "                .scatter_add_(-1, my_index[:, None, :, :].broadcast_to(b, n, m, dy), g_dense)\n",
    "            #P_dense[c_mask == 0] = 0 # I dont think i actually want that. \n",
    "            P_dense= log_P_dense.exp()\n",
    "            P = re_project_C(P_dense, c_index)    \n",
    "            #P = log_P.exp() #b, n, m, n, m\n",
    "            # f  (b, n, m, n)\n",
    "            # F = torch.einsum(\"bijl->bijil\", f) #doesnt work but that’s the idea\n",
    "            F = torch.permute(f, (0, 2, 3, 1)) #bijl -> bjli\n",
    "            F = double_last_dimension(F) #bjlii\n",
    "            F = torch.permute(F, (0, 3, 1, 4, 2)) #bijil\n",
    "            # (n, m, n, n)\n",
    "            # g (b, n, m, m)\n",
    "            # G = torch.einsum(\"bijl->bijjl\", g) #(n, m, m, m)\n",
    "            G = torch.permute(g, (0, 1, 3, 2)) #bijl -> bilj\n",
    "            G = double_last_dimension(G) #biljj\n",
    "            G = torch.permute(G, (0, 1, 3, 4, 2)) #bijjl \n",
    "        \n",
    "            mymatrix = torch.eye(n*m, device=device)[None, ...] - one_minus_delta * P.reshape(b, n*m, n*m) \n",
    "            # b, n*m, n*m\n",
    "            \n",
    "            #print(torch.det(mymatrix))\n",
    "            #print(mymatrix)\n",
    "            #see paper for a proof this is diagonally dominant, thus invertible\n",
    "            Delta = delta * torch.inverse(mymatrix)\n",
    "            Gamma = one_minus_delta * torch.linalg.solve(mymatrix, F.reshape(b, n*m, n*n))\n",
    "            Theta = one_minus_delta * torch.linalg.solve(mymatrix, G.reshape(b, n*m, m*m))\n",
    "            \n",
    "            Delta = Delta.reshape(b, n, m, n, m)\n",
    "            Gamma = Gamma.reshape(b, n, m, n, n) \n",
    "            Theta = Theta.reshape(b, n, m, m, m)\n",
    "\n",
    "            d_cost_matrix = torch.einsum(\"bijkl,bij->bkl\", Delta, grad_output)\n",
    "            d_mx = torch.einsum(\"bijkl,bij->bkl\", Gamma, grad_output)\n",
    "            d_my = torch.einsum(\"bijkl,bij->bkl\", Theta, grad_output)\n",
    "                        \n",
    "            d_mx = d_mx - d_mx.mean(-1, keepdims=True)# normalize the markov gradients to stay in the markov space\n",
    "            d_my = d_my - d_my.mean(-1, keepdims=True)        \n",
    "        return (d_mx, d_my, d_cost_matrix, *[None]*8 )\n",
    "\n",
    "mx = mx.detach().requires_grad_()\n",
    "my = my.detach().requires_grad_()\n",
    "C = C.detach().requires_grad_()\n",
    "\n",
    "C_infty = DiscountedWlCostMatrixSparse.apply(mx, my, C)\n",
    "C_infty.sum().backward()\n",
    "\n",
    "mx_new_grad = mx.grad.detach().clone()\n",
    "my_new_grad = my.grad.detach().clone()\n",
    "C_new_grad = C.grad.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ffabcd56-c166-4426-b00f-d89aebece25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:iteration: time elapsed 1.5979630313813686s\n",
      "INFO:root:iteration: time elapsed 1.5599573720246553s\n",
      "INFO:root:iteration: time elapsed 1.2026522997766733s\n",
      "INFO:root:iteration: time elapsed 1.4931569267064333s\n",
      "INFO:root:iteration: time elapsed 1.4285323228687048s\n",
      "INFO:root:iteration: time elapsed 1.390657739713788s\n",
      "INFO:root:iteration: time elapsed 1.5235140081495047s\n",
      "INFO:root:iteration: time elapsed 1.3720796387642622s\n",
      "INFO:root:iteration: time elapsed 1.358828354626894s\n",
      "INFO:root:iteration: time elapsed 1.4717292338609695s\n"
     ]
    }
   ],
   "source": [
    "mx = mx.detach().requires_grad_()\n",
    "my = my.detach().requires_grad_()\n",
    "C = C.detach().requires_grad_()\n",
    "C_infty2 = DiscountedWlCostMatrix.apply(mx, my, C)\n",
    "C_infty2.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5609ddcd-d2a9-48ac-9a9d-a9bcde6885c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAGhCAYAAADm21ehAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMz0lEQVR4nO3de1zUVf4/8NcMlwG5I8jFC6Bo4GpqqISpWLLeWpNqNYoWL4VpUSplShfNrNBy1crStS2z1lttWtoW5QXXLBSFyvJueEsuiigoyHCZ8/vDn7MNl8/w4XyAke/ruY/P47HMmXnNmWkc3pxzPuejE0IIEBERETWQvqU7QERERDcXFg9ERESkCosHIiIiUoXFAxEREanC4oGIiIhUYfFAREREqrB4ICIiIlVYPBAREZEqLB6IiIhIFfuW7sANuReKpDN0Op10hqO9nXRG9sk86QwAiOzoJZ1RXVYqnVHs4Cqd4e2gzUamY97eIp2xOfl+6YzL+3dLZ5Tf0k86AwBOXbgsnRHs6ymd4eniJJ0BAJdLy6Uz2mnweTOez5XO+PqCSToDAO7p1k46Q1RXSWcU2btIZ7jkHpfOAICAfgM1yanP4Xde0Swr/IkXNMuyFTZTPBAREdkMDf4Ybc04bUFERESqcOSBiIioBp2Of1sr4btDREREqrB4ICIiIlU4bUFERFQTF0wqYvFARERUE9c8KFJdPBQWFuKDDz5ARkYG8vPzAQD+/v4YMGAAJkyYAF9fX807SURERLZDVWm1b98+dOvWDW+99RY8PDwwePBgDB48GB4eHnjrrbcQFhaG/fv3N1VfiYiImoVOr9PsaI1UjTw8+eSTGDt2LFasWFFrN0chBKZMmYInn3wSGRkZijlGoxFGo7HWbQaDQU13iIiImgbXPChSNfLw888/Y8aMGXVuA63T6TBjxgz89NNPVnNSU1Ph4eFhcSx7c6marhAREVELUTXy4O/vj8zMTISFhdXZnpmZCT8/P6s5KSkpSE5OtrjtYon8NRiIiIio6akqHp555hlMnjwZWVlZGDp0qLlQKCgowPbt2/Hee+9h0aJFVnMMBkOtKYqrRvmLthAREWmCZ1soUlU8PPHEE/Dx8cGSJUvw7rvvorq6GgBgZ2eHiIgIfPjhhxg3blyTdJSIiKi5aHGV5tZM9amaDzzwAB544AFUVlaisLAQAODj4wMHBwfNO0dERES2p9GbRDk4OCAgIEDLvhAREdkGPactlHCHSSIioho4baGMpRURERGpwuKBiIiIVOG0BRERUU08VVMR3x0iIiJSxWZGHq5Vym8S1c7VSTqjtLJaOqOzn5d0BgBcrJRfsHOxXL4+7OQqfxruDyfzpTMA4JPpf5XOEFWV0hll3fpKZ+w5dlY6AwB6BVnf1dWatm7O0hnlFdps9Obj1kY6o7D0mnSGW/vO0hljfMukMwCg3EH+v8+5oivSGd285Pvx7xJtrmE0UZMUBVwwqchmigciIiJboeOpmopYPBAREdXENQ+K+O4QERGRKiweiIiIbMg777yD4OBgODk5ITIyEpmZmfXe97333sOgQYPg5eUFLy8vxMTEKN5fKyweiIiIatDpdJodamzYsAHJycmYO3cusrOz0atXLwwfPhznz5+v8/47d+7Egw8+iPT0dGRkZKBjx44YNmwYzp07p8XbUC8WD0RERDZi8eLFSExMxMSJE9G9e3esWLECbdq0wQcffFDn/desWYPHH38cvXv3RlhYGP75z3/CZDJh+/btTdpPLpgkIiKqSa/dqZpGoxFGo9HiNoPBAIPB8rTViooKZGVlISUl5X/d0OsRExODjIyMBj1XWVkZKisr4e3tLd9xBRx5ICIiqkmn1+xITU2Fh4eHxZGamlrrKQsLC1FdXQ0/P8u9W/z8/JCf37C9cmbNmoXAwEDExMRo8jbUR/Pi4ezZs5g0aZLWsURERDellJQUFBcXWxx/HF3QyoIFC7B+/Xps2rQJTk7ymyYq0XzaoqioCKtXr653fgaoewjHaDTWGsIhIiJqCVpekruuKYq6+Pj4wM7ODgUFBRa3FxQUwN/fX/GxixYtwoIFC7Bt2zbceuutUv1tCNXFw+bNmxXbc3JyrGakpqZi3rx5Frc9mfwMpj09U213iIiItNcCm0Q5OjoiIiIC27dvR2xsLACYFz8mJSXV+7jXX38dr776Kr755hv07Su/dX5DqC4eYmNjodPpIISo9z7WKraUlBQkJydb3Pb7xWK1XSEiImpVkpOTMX78ePTt2xf9+/fH0qVLUVpaiokTr1/NIyEhAe3btzevmVi4cCHmzJmDtWvXIjg42Lw2wtXVFa6urk3WT9WlVUBAADZu3AiTyVTnkZ2dbTXDYDDA3d3d4uCUBRER/V/3wAMPYNGiRZgzZw569+6Nn376CWlpaeZFlGfOnEFeXp75/suXL0dFRQX++te/IiAgwHwsWrSoSfupeuQhIiICWVlZGDNmTJ3t1kYliIiIbJ6Gp2qqlZSUVO80xc6dOy1+PnXqVNN3qA6qi4eZM2eitLS03vbQ0FCkp6dLdYqIiKgl6XhhLEWqi4dBgwYptru4uCA6OrrRHSIiIiLbxh0miYiIatLwVM3WiMUDERFRDZy2UMZ3h4iIiFRh8UBERESq2My0RZtzx6QzyhwcpDNEh27SGY52dtIZAOBmKpfOOFEqn3GLv5d0Rkg7T+kMAHAw1n+mT0OVX2jYBWaUOPt2ks7o0bGddAYABLvIf95e39KwK/YpeToqWDoDAMovFli/kxXtbpHfnvfa7yelM+w6dpHOAABDyWXpDHs7+b8VS37aI51xf/8o6YxmwTUPijjyQERERKrYzMgDERGRzWjBTaJuBiweiIiIauDZFsr47hAREZEqHHkgIiKqiQsmFXHkgYiIiFThyAMREVFNXPOgiO8OERERqcKRByIiohp0XPOgSPXIw7Vr17B7924cOnSoVlt5eTk++ugjqxlGoxElJSUWh7GiQm1XiIiImoZer93RCql6VceOHUN4eDgGDx6Mnj17Ijo6Gnl5eeb24uJiTJw40WpOamoqPDw8LI63P/yX+t4TERFRs1NVPMyaNQs9evTA+fPncfToUbi5ueGOO+7AmTNnVD1pSkoKiouLLY4nJzysKoOIiKip6HQ6zY7WSNWahx9++AHbtm2Dj48PfHx8sGXLFjz++OMYNGgQ0tPT4eLi0qAcg8EAg8FgcVupo6OarhAREVELUTXycO3aNdjb/6/e0Ol0WL58OUaPHo3o6GgcOyZ/ZUwiIiKybapGHsLCwrB//36Eh4db3L5s2TIAwD333KNdz4iIiFpKK51u0IqqkYd7770X69atq7Nt2bJlePDBByGE0KRjRERELUan1+5ohVS9qpSUFHz11Vf1tr/77rswmUzSnSIiIiLbxU2iiIiIatDpOW2hhMUDERFRTa10ukErfHeIiIhIFRYPREREpIrNTFsYut0qnSEK86zfyYpf8y5KZ/h7ukpnAIChgZtuKSkuK5TOOFN0VTpDq/ekrLJKOsO5U1fpjAuXrkhneLo4SWcAwFW9nXRGct9A6Yw8vTb/jQO6BUhnHL9QLJ3h7OovnXHssLrdd+vjYpDfRE+LxexnnNpLZ3S/ck06AwDc3dw0yakXT9VUZDPFAxERka3Qcc2DIr47REREpApHHoiIiGritIUiFg9EREQ1cJ8HZZy2ICIiIlVYPBAREZEqnLYgIiKqiWdbKOK7Q0RERKqoLh4OHz6MVatW4ciRIwCAI0eOYOrUqZg0aRJ27NiheQeJiIianU6n3dEKqZq2SEtLw5gxY+Dq6oqysjJs2rQJCQkJ6NWrF0wmE4YNG4Zvv/0Wd911l2KO0WiE0WisdZvBYFD/CoiIiDTGTaKUqXp3Xn75ZcycORMXL17EqlWr8NBDDyExMRFbt27F9u3bMXPmTCxYsMBqTmpqKjw8PCyOpYsXN/pFEBERaUqv0+5ohVQVDwcPHsSECRMAAOPGjcOVK1fw17/+1dweHx+PAwcOWM1JSUlBcXGxxTE9OVldz4mIiKhFqD7bQvf/52/0ej2cnJzg4eFhbnNzc0NxsfUL0hgMhlpTFFWiRG1XiIiIqAWoGnkIDg7G8ePHzT9nZGSgU6dO5p/PnDmDgAD5K+IRERG1KJ1eu6MVUvWqpk6diurqavPPPXr0gL39/wYvvv76a6uLJYmIiKh+77zzDoKDg+Hk5ITIyEhkZmbWe9+DBw/i/vvvR3BwMHQ6HZYuXdosfVQ1bTFlyhTF9tdee02qM0RERLZA10KnWG7YsAHJyclYsWIFIiMjsXTpUgwfPhxHjx5Fu3btat2/rKwMnTt3xtixYzFjxoxm62frHE8hIiKS0ULTFosXL0ZiYiImTpyI7t27Y8WKFWjTpg0++OCDOu/fr18/vPHGG4iLi2vW7Q5YPBARETUho9GIkpISi6PmXkcAUFFRgaysLMTExJhv0+v1iImJQUZGRnN22SoWD0RERDXodDrNjrr2NkpNTa31nIWFhaiuroafn5/F7X5+fsjPz2+ul94gvDAWERFRE0pJSUFyjb2MbvYdlVk8EBERNaG69jaqi4+PD+zs7FBQUGBxe0FBAfz9/Zuqe41iM8WDfVWFdIbJxU06Q3etTDpj74lz0hkA8JfbukpnGKuqrd/JipJrtefm1OrQxk46AwAq9I7SGcaqKukMLd4TF4ODdAYAVFWbpDOueMh/MVWVlUtnaMXH1Vk642jeRemMiBBt9r35+XSB9TtZUanB56RzOy/5fmjwndQsWmBbaUdHR0RERGD79u2IjY0FAJhMJmzfvh1JSUnN3h8lNlM8EBER2YwW2twpOTkZ48ePR9++fdG/f38sXboUpaWlmDhxIgAgISEB7du3N6+ZqKiowKFDh8z//9y5c/jpp5/g6uqK0NDQJusniwciIqIaWmqfhwceeAAXLlzAnDlzkJ+fj969eyMtLc28iPLMmTPQ6/9X2OTm5qJPnz7mnxctWoRFixYhOjoaO3fubLJ+snggIiKyIUlJSfVOU9QsCIKDgyGEaIZeWWLxQEREVFMrvSaFVvjuEBERkSosHoiIiEgVTaYthBAttriEiIhIcy1wqubNRJORB4PBgMOHD2sRRURE1OJ0Or1mR2ukauSh5vaaN1RXV2PBggVo27YtgOtXBSMiIqLWSVXxsHTpUvTq1Quenp4WtwshcPjwYbi4uDRo+sJoNNa6opjRaLzp9/omIqJWglPxilSNp7z22msoLi7Giy++iPT0dPNhZ2eHDz/8EOnp6dixY4fVnLquMLZ46ZuNfhFERERa0vKqmq2RquJh9uzZ2LBhA6ZOnYpnnnkGlZWVjXrSlJQUFBcXWxzJ06c1KouIiIial+qVHP369UNWVhYuXLiAvn374tdff1VdWRkMBri7u1scnLIgIiK6OTTqVE1XV1esXr0a69evR0xMDKqrb5KrpBERETVEKz1LQitS+zzExcVh4MCByMrKQlBQkFZ9IiIialnc50GR9CZRHTp0QIcOHbToCxEREd0EeGEsIiKiGlrr5k5aYfFARERUUys9xVIrLK2IiIhIFRYPREREpAqnLYiIiGrimgdFNlM8VNo5Smfoy65KZ3S3vyad4Xvoa+kMALh45nvpjBEDh0tnnDLZSWfkb1kjnQEAhlF/k86o2vFv6YyuEQOlM1As/3kFgKtHf5HOcIiS/5x0qLwsnQEA5Qfkr9DbJkD+DDBXJ2fpjP05edIZAHC7fbF0hs5R/t+xo6O7dIZwc5POoJZnM8UDERGRrWit16TQCosHIiKimvSctlDCd4eIiIhU4cgDERFRDZy2UMaRByIiIlKFIw9EREQ1ceRBEUceiIiISBWOPBAREdXETaIUSRUPpaWl+OSTT3DixAkEBATgwQcfRNu2bbXqGxERUYvQ6TltoURV8dC9e3fs3r0b3t7eOHv2LAYPHoxLly6hW7du+O233zB//nzs2bMHISEhijlGoxFGo7HWbQaDQf0rICIiomalalzmyJEjqKqqAgCkpKQgMDAQp0+fRmZmJk6fPo1bb70Vzz//vNWc1NRUeHh4WBxLlyxu3CsgIiLSmk6v3dEKNXraIiMjAytWrICHhwcAwNXVFfPmzUNcXJzVx6akpCA5OdnitqvXjPXcm4iIiGyJ6uLhxsYZ5eXlCAgIsGhr3749Lly4YDXDYDDUmqKoNJWo7QoRERG1ANXFw9ChQ2Fvb4+SkhIcPXoUPXr0MLedPn2aCyaJiOjmx30eFKkqHubOnWvxs6urq8XPW7ZswaBBg+R7RURE1IJ0rXStglakioea3njjDanOEBERke3jJlFEREQ1cdpCEYsHIiKiGrhJlDJO6hAREZEqLB6IiIhIFZ0QQrR0JwDg0pmT0hnXfpfPMIX2ks5wdnSQzgAA/dXL0hkVFwukM3QazP1d8uognQEAbY7slc5w9PWXzqi4kC+d4XDbYOkMAGiDaumMyuJL0hmOPn7SGQAgqiqlM44VXpXOCGnnJZ1hPLRfOgMAqsvkX4+dcxvpjKLAcOmMTj7u0hkA4O7mpklOfUouFmqW5d7WR7MsW8E1D0RERDVxwaQiTlsQERGRKhx5ICIiqoGbRCnju0NERFSTXqfdodI777yD4OBgODk5ITIyEpmZmYr3//TTTxEWFgYnJyf07NkTX331VWNfdYOxeCAiIrIRGzZsQHJyMubOnYvs7Gz06tULw4cPx/nz5+u8/w8//IAHH3wQjzzyCH788UfExsYiNjYWv/76a5P2k8UDERGRjVi8eDESExMxceJEdO/eHStWrECbNm3wwQcf1Hn/N998EyNGjMDMmTMRHh6O+fPn47bbbsOyZcuatJ8sHoiIiGrS6TU7jEYjSkpKLA6j0VjrKSsqKpCVlYWYmBjzbXq9HjExMcjIyKizmxkZGRb3B4Dhw4fXe3+tsHggIiJqQqmpqfDw8LA4UlNTa92vsLAQ1dXV8POz3DPFz88P+fl17y2Tn5+v6v5a4dkWRERENQgN93lISUlBcnKyxW0Gg0Gz/JagauQhOzsbJ0/+bxfHjz/+GHfccQc6duyIgQMHYv369Q3KaegQDhERUUuoNml3GAwGuLu7Wxx1FQ8+Pj6ws7NDQYHlzsAFBQXw9697Z1x/f39V99eKquJh4sSJ+O233wAA//znP/HYY4+hb9++eP7559GvXz8kJibWu6jjj+oawlny7vLGvQIiIiKNCQ3/11COjo6IiIjA9u3bzbeZTCZs374dUVFRdT4mKirK4v4AsHXr1nrvrxVV0xbHjx9H165dAQDvvvsu3nzzTSQmJprb+/Xrh1dffRWTJk1SzKlrCKesIFdNV4iIiFqd5ORkjB8/Hn379kX//v2xdOlSlJaWYuLEiQCAhIQEtG/f3rxmYtq0aYiOjsbf//533H333Vi/fj3279+PlStXNmk/VRUPbdq0QWFhIYKCgnDu3Dn079/foj0yMtJiWqM+BoOh1pBN9eWLarpCRETU6jzwwAO4cOEC5syZg/z8fPTu3RtpaWnmRZFnzpyBXv+/SYMBAwZg7dq1eOGFF/Dcc8+ha9eu+Pzzz9GjR48m7aeq4mHkyJFYvnw5/vnPfyI6Ohr//ve/0avX/65C+cknnyA0NFTzThIRETWnlrzedFJSEpKSkups27lzZ63bxo4di7FjxzZxryypKh4WLlyIO+64A9HR0ejbty/+/ve/Y+fOnQgPD8fRo0exZ88ebNq0qan6SkRERDZA1YLJwMBA/Pjjj4iKikJaWhqEEMjMzMS3336LDh064Pvvv8eoUaOaqq9ERETNwiSEZkdrpHqfB09PTyxYsAALFixoiv4QERG1ONFKf+lrhTtMEhERkSrcYZKIiKiG1jrdoBWOPBAREZEqLB6IiIhIFZ2wkVUhJ/MuSGc4OcjPwrSplr/GRgkcpDMAwEODmMpLhdIZpS5tpTPyLl+VzgAAH/c20hluF3+XzrB395TPcHGVzgAAo538BXac7OQvAiSqKqUzAKBSL//B11+9LJ1RdUU+46pngHQGALTJ+006wxDYSTpD7yj/Wbt2Nkc6AwD8evXTJKc+eYWXNMsK8PHSLMtWcM0DERFRDTbyd7XNYvFARERUAxdMKuOaByIiIlKFIw9EREQ1cOBBGUceiIiISBUWD0RERKQKpy2IiIhq4NkWylg8EBER1cCzLZSpmrZ48skn8d133zVVX4iIiOgmoKp4eOeddzBkyBB069YNCxcuRH5+fqOe1Gg0oqSkxOIwGuV3diQiItKC0PBojVQvmPz2228xatQoLFq0CJ06dcKYMWPw5ZdfwmQyNTgjNTUVHh4eFsfyt99U2xUiIqImYRJCs6M1Ul089OzZE0uXLkVubi7+9a9/wWg0IjY2Fh07dsTzzz+PEydOWM1ISUlBcXGxxTH1yWmNegFERETUvBp9qqaDgwPGjRuHtLQ05OTkIDExEWvWrMEtt9xi9bEGgwHu7u4Wh8Egf8EVIiIianqa7PPQqVMnvPTSSzh58iTS0tK0iCQiImoxQgjNjtZI1amaQUFBsLOzq7ddp9Phz3/+s3SniIiIWlIr/Z2vGVXFw8mTJ5uqH0RERHST4CZRRERENbTWsyS0wuKBiIiohta6VkErvDAWERERqcLigYiIiFThtAUREVENnLVQZjPFg8G+/lNAG8reTn4g5YJRJ51RZiyXzgAAN2f5jJPVTvL9qKySzghv31Y6AwDKKuT7cqVtB+mMtrpK6YxPfzwlnQEAd9zSUTrDQYN/f2t2/yKdAQATo3tLZzhfuyqd4eQv/74aKxu+bb8Shy7dpTOqNfhlWF5dLZ3h4OYp3xFqcTZTPBAREdkKnm2hjMUDERFRDTzbQhkXTBIREZEqHHkgIiKqwcSBB0UceSAiIiJVOPJARERUgwCHHpRw5IGIiIhU4cgDERFRDTzbQpnqkYdly5YhISEB69evBwB8/PHH6N69O8LCwvDcc8+hqkp+Ex8iIqKWZBLaHa2RqpGHV155Ba+//jqGDRuGGTNm4PTp03jjjTcwY8YM6PV6LFmyBA4ODpg3b55ijtFohNForHWbwWBQ/wqIiIioWakqHj788EN8+OGHuO+++/Dzzz8jIiICq1evRnx8PAAgLCwMzz77rNXiITU1tdZ9kp95Fk8/O0tl94mIiLTHaQtlqoqH3Nxc9O3bFwDQq1cv6PV69O7d29x+2223ITc312pOSkoKkpOTLW67WFKqpitERETUQlStefD398ehQ4cAAMePH0d1dbX5ZwA4ePAg2rVrZzXHYDDA3d3d4uCUBRER0c1BVfEQHx+PhIQEJCYmYvjw4Xj22WfxzDPPYMWKFfjHP/6BKVOm4N57722qvhIRETULIYRmR1MpKipCfHw83N3d4enpiUceeQRXrypfUXblypUYMmQI3N3dodPpcPny5UY9t6ppi3nz5sHZ2RkZGRlITEzE7Nmz0atXLzz77LMoKyvD6NGjMX/+/EZ1hIiIyFbcDFfVjI+PR15eHrZu3YrKykpMnDgRkydPxtq1a+t9TFlZGUaMGIERI0YgJSWl0c+tqnjQ6/V47rnnLG6Li4tDXFxcoztARERE6hw+fBhpaWnYt2+feS3i22+/jVGjRmHRokUIDAys83HTp08HAOzcuVPq+bnDJBERUQ1CaHcYjUaUlJRYHDW3K1ArIyMDnp6e5sIBAGJiYqDX67F3717Zl28ViwciIqIaTEJodqSmpsLDw8PiSE1Nlepffn5+rRMU7O3t4e3tjfz8fKnshmDxQERE1IRSUlJQXFxscdS33mD27NnQ6XSKx5EjR5r5FdTGa1sQERE1IYPB0ODtCJ5++mlMmDBB8T6dO3eGv78/zp8/b3F7VVUVioqK4O/v39iuNhiLByIiohpaaodJX19f+Pr6Wr1fVFQULl++jKysLERERAAAduzYAZPJhMjIyKbupu0UDxeulElnuDo5Smf42FVLZ+h93aUzAKDwm8+kM/wGjZbOcHFykM4oulounQEAHpXK5zA3hIuHl3RGsdFOOqNXkJ90BgD4Qf69rXL2ls548vbO0hkAUHn+tHRGcdsO0hkXzxdLZ4T5uklnAEBxeaV0RhuD/L9jff4p6Yzvrsj3AwBitfm41cvWz9QMDw/HiBEjkJiYiBUrVqCyshJJSUmIi4szn2lx7tw5DB06FB999BH69+8P4Ppaifz8fJw4cQIA8Msvv8DNzQ2dOnWCt3fDvwe45oGIiOgmtGbNGoSFhWHo0KEYNWoUBg4ciJUrV5rbKysrcfToUZSV/e+P8xUrVqBPnz5ITEwEAAwePBh9+vTB5s2bVT23zYw8EBER2YqbYZMob29vxQ2hgoODa02/vPTSS3jppZekn5vFAxERUQ0Ctl88tCROWxAREZEqHHkgIiKq4SaYtWhRHHkgIiIiVTjyQEREVMPNsGCyJakuHvLy8rB8+XLs3r0beXl50Ov16Ny5M2JjYzFhwgTY2cmf/05ERES2S9W0xf79+xEeHo6vvvoKlZWVOH78OCIiIuDi4oJnnnkGgwcPxpUrV6zm1HWFsQrJK4wRERFpRQih2dEaqSoepk+fjhkzZmD//v347rvv8OGHH+LYsWNYv349cnJyUFZWhhdeeMFqTl1XGHt/xTuNfhFERERaMgntjtZIVfGQnZ2Nv/3tb+afH3roIWRnZ6OgoABeXl54/fXX8e9//9tqTl1XGHtkyhPqe09ERETNTtWah3bt2iEvLw+dO1/fVLygoABVVVVwd79+LYeuXbuiqKjIak5dVxhzLCxR0xUiIqIm01qnG7SiauQhNjYWU6ZMQVpaGtLT0xEfH4/o6Gg4OzsDAI4ePYr27ds3SUeJiIjINqgaeXjllVeQl5eH0aNHo7q6GlFRUfjXv/5lbtfpdEhNTdW8k0RERGQ7VBUPrq6u2LBhA8rLy1FVVQVXV1eL9mHDhmnaOSIiopbAaQtljdokysnJSet+EBER2YzWepaEVrg9NREREanC7amJiIhq4LSFMhYPRERENfDaFso4bUFERESq2MzIQ4i7o3RG1RX5jaaMxRelMy7v2yWdAQBuPfpKZ7QxlUtnXC4zSWfof/leOgMAdLf2l84ozpbvi1NAJ+mMTpWV0hkAUH75qnSGSxsX6YyrZ3+TzgAAnZ2DdIa3R6l0hnBtI52h0+hCgZU7v5DOsBvwZ+kMxw4h0hmD+Tdrq2AzxQMREZGt4KSFMhYPRERENXDBpDKOHxEREZEqHHkgIiKqgWdbKGPxQEREVANrB2WNKh4qKirw+eefIyMjA/n5+QAAf39/DBgwAGPGjIGjo/yZE0RERGSbVK95OHHiBMLDwzF+/Hj8+OOPMJlMMJlM+PHHH5GQkIA//elPOHHiRFP0lYiIiGyA6pGHqVOnomfPnvjxxx/h7u5u0VZSUoKEhAQ88cQT+OabbzTrJBERUXPi2RbKVBcP33//PTIzM2sVDgDg7u6O+fPnIzIyUpPOERERke1RXTx4enri1KlT6NGjR53tp06dgqenp2KG0WiE0WisdZvBYFDbHSIiIs3xbAtlqtc8PProo0hISMCSJUtw4MABFBQUoKCgAAcOHMCSJUswYcIETJ48WTEjNTUVHh4eFsfiN99q9IsgIiLSkhBCs6M1Uj3y8PLLL8PFxQVvvPEGnn76aeh0OgDX32h/f3/MmjULzz77rGJGSkoKkpOTLW4zXilW2xUiIqImYWqdv/M106hTNWfNmoVZs2bh5MmTFqdqhoQ07KIpBoOh1hRFSYX8BZyIiIio6UltTx0SEoKoqChERUWZC4ezZ89i0qRJmnSOiIiIbI/m17YoKirC6tWrtY4lIiJqNlzzoEz1tMXmzZsV23NychrdGSIiIrJ9qouH2NhY6HQ6xWrqxiJKIiKim1FrHTHQiuppi4CAAGzcuNG8LXXNIzs7uyn6SURE1GxMGh6tkeriISIiAllZWfW2WxuVICIiopub6mmLmTNnorS0tN720NBQpKenS3WKiIioJfGPYGWqi4dBgwYptru4uCA6OrrRHSIiIiLbphM2Ul5duXSppbsAAKguL5POsGvjokFPAFO5/MZZx4uN1u9kxfZfT0pnPHrXbdIZAJB/+ap0RrUGW8e193aTznCw02ZhcZUGr+fg2QvSGcG+ntIZAHC+pP6RzYbq5ucpnVFVclk649ODedIZAPDnWztLZ2hxrYbzxfL/bXr4e0pnAICbl5cmOfVZ81/t1u/FR2vz/WdLGrXDJBERUWtmI39X2ywWD0RERDXw2hbKNN9hkoiI6GZ3M+wwWVRUhPj4eLi7u8PT0xOPPPIIrl6tf2q3qKgITz75JG655RY4OzujU6dOeOqpp1BcrP7ClCweiIiIbkLx8fE4ePAgtm7dii+//BK7du3C5MmT671/bm4ucnNzsWjRIvz666/48MMPkZaWhkceeUT1c3PagoiIqAYtFpg2pcOHDyMtLQ379u1D3759AQBvv/02Ro0ahUWLFiEwMLDWY3r06IHPPvvM/HOXLl3w6quv4uGHH0ZVVRXs7RteEmg+8lBQUICXX35Z61giIqKbktFoRElJicVhNMqdCZeRkQFPT09z4QAAMTEx0Ov12Lt3b4NziouL4e7urqpwAJqgeMjPz8e8efO0jiUiIroppaamwsPDw+JITU2VyszPz0e7du0sbrO3t4e3tzfy8/MblFFYWIj58+crTnXUR/W0xYEDBxTbjx49qroTREREtkTLWYuUlBQkJydb3GYwGOq87+zZs7Fw4ULFvMOHD0v3qaSkBHfffTe6d++Ol156SfXjVRcPvXv3rvf6FTdu51U1iYjoZqblWRIGg6HeYqGmp59+GhMmTFC8T+fOneHv74/z589b3F5VVYWioiL4+/srPv7KlSsYMWIE3NzcsGnTJjg4ODSob3+kunjw9vbG66+/jqFDh9bZfvDgQYwePVoxw2g01prvqTAaG/zmEhERtUa+vr7w9fW1er+oqChcvnwZWVlZiIiIAADs2LEDJpMJkZGR9T6upKQEw4cPh8FgwObNm+Hk5NSofjbqqpq5ubkICgqq82jfvr3Viq2u+Z+/L1nSqBdARESkNZMQmh1NITw8HCNGjEBiYiIyMzPx/fffIykpCXFxceYzLc6dO4ewsDBkZmYCuF44DBs2DKWlpXj//fdRUlKC/Px85Ofno7q6WtXzqx55mDJliuJVNTt16oRVq1YpZtQ1/1NRJn9NCSIiIi3Y+JmaAIA1a9YgKSkJQ4cOhV6vx/3334+33nrL3F5ZWYmjR4+i7P//fs3OzjafiREaGmqRdfLkSQQHBzf4uVUXD/fee69iu5eXF8aPH694n7rmf66orHqIiIj+L/P29sbatWvrbQ8ODraYCRgyZIhmazk0P1Xz7NmzmDRpktaxREREZCM0Lx6KioqwevVqrWOJiIiaja2veWhpqqctNm/erNiek5PT6M4QERHZgtb6S18rqouH2NjYevd5uIH7PBAREbVeqqctAgICsHHjRphMpjqP7OzspugnERFRs7kZLsndkhq1z0NWVla97dZGJYiIiGydENodrZHqaYuZM2cq7vMQGhqK9PR0qU4RERGR7VJdPAwaNEix3cXFBdHR0Y3uEBEREdk21cWDLRPVldIZ5Y5tpDOKS8qlMwDA+0qBdEaX9p2lMzq0dZfOKDPK/7cBAC+Xxu3D/kfGKvkNybRYib3neK50BgD07RIonXGtQv6/j1bTlR01+LydLLwindHeJL/r7bheHaUzAKDcQf6r2rm6QjrD10/+v83He45IZwDA4yOjNMmpD8+2UKb5Pg9ERETUurWqkQciIiItCHDkQQmLByIioho4a6GM0xZERESkCkceiIiIauCCSWWNHnn4/fffcfXq1Vq3V1ZWYteuXVKdIiIiItulunjIy8tD//79ERQUBE9PTyQkJFgUEUVFRbjzzjs17SQREVFz4vbUylQXD7Nnz4Zer8fevXuRlpaGQ4cO4c4778SlS5fM92mtbxYRERE1Ys3Dtm3bsGnTJvTt2xcA8P3332Ps2LG46667sH37dgC8qiYREd3cuOZBmeqRh+LiYnh5eZl/NhgM2LhxI4KDg3HnnXfi/PnzVjOMRiNKSkosDqPRqLYrRERETYIXxlKmunjo3LkzDhw4YHGbvb09Pv30U3Tu3Bl/+ctfrGakpqbCw8PD4vj7kiVqu0JEREQtQHXxMHLkSKxcubLW7TcKiN69e1td85CSkoLi4mKL4+kZM9R2hYiIqElwwaQy1WseXn31VZSV1X3BGHt7e3z22Wc4d+6cYobBYIDBYLC47Uq1/MWKiIiIqOmpHnmwt7eHu3v9V1bLy8vDvHnzpDpFREREtkvz7amLioqwevVqrWOJiIiajUkIzY7WSPW0xebNmxXbc3JyGt0ZIiIiW9BKf+drRnXxEBsbC51Op7gIhPs8EBERtV6qpy0CAgKwceNGmEymOo/s7Oym6CcREVGz4dkWylQXDxEREcjKyqq33dqoBBERka3jmgdlqqctZs6cidLS0nrbQ0NDkZ6eLtUpIiIisl2qi4dBgwYptru4uCA6OrrRHSIiIiLbprp4aCqVejvpDHt7+ZfjXFb/qEpDna/UZsMre9f699NoKFNhrnSGi3c76YwqY4l0BgDYe7aVznB2dJDO0JVels6oqDZJZwCAvuyKdMbtwb7SGcYC5c3hGsrexU06I6Stl/U7WVFxQf59rbxUKJ0BAE4afO4rNOiLqfyadMaDf/KXzmgOrXOyQTs2UzwQERHZita6VkErmm8SRURERK0bRx6IiIhq4FmDylg8EBER1cDaQVmjioeLFy/iwIED6NWrF7y9vVFYWIj3338fRqMRY8eORXh4uNb9JCIiIhuhunjIzMzEsGHDUFJSAk9PT2zduhVjx46Fvb09TCYTFixYgN27d+O2225riv4SERFRC1O9YPL555/H2LFjUVxcjOeeew6xsbEYOnQojh07hhMnTiAuLg7z589vir4SERE1C+4wqUx18ZCVlYXk5GS4ublh2rRpyM3NRWJiork9KSkJ+/bt07STREREZDtUT1tUVFTA2dkZAODg4IA2bdrAx8fH3O7j44OLFy8qZhiNRhiNxlq3GQwGtd0hIiLSHM+2UKZ65KFjx47Iyckx/7x+/XoEBASYf87Ly7MoJuqSmpoKDw8Pi2Pp4sVqu0JERNQkhNDuaI1UjzzExcXh/Pnz5p/vvvtui/bNmzejf//+ihkpKSlITk62uK203FjPvYmIiJpXa12roBXVxcPcuXMV259//nnY2Slfp8JgMNSaoqgS2lz7gIiIiJqW5ttTX7x4EVOnTtU6loiIiP6gqKgI8fHxcHd3h6enJx555BFcvXpV8TGPPfYYunTpAmdnZ/j6+mLMmDE4cuSI6ufWvHgoKirC6tWrtY4lIiJqNkIIzY6mEh8fj4MHD2Lr1q348ssvsWvXLkyePFnxMREREVi1ahUOHz6Mb775BkIIDBs2DNXV6q4GrXraYvPmzYrtf1xMSURERNo7fPgw0tLSsG/fPvTt2xcA8Pbbb2PUqFFYtGgRAgMD63zcH4uL4OBgvPLKK+jVqxdOnTqFLl26NPj5VRcPsbGx0Ol0itWUTqdTG0tERGQzTBoOGNS1PUFda//UyMjIgKenp7lwAICYmBjo9Xrs3bsX9957r9WM0tJSrFq1CiEhIejYsaOq51c9bREQEICNGzfCZDLVeWRnZ6uNJCIisilCw//VtT1BamqqVP/y8/PRrl07i9vs7e3h7e2N/Px8xce+++67cHV1haurK77++mts3boVjo6Oqp5fdfEQERGBrKysetutjUoQERH9X5KSkoLi4mKLIyUlpc77zp49GzqdTvFozALHP4qPj8ePP/6I//73v+jWrRvGjRuH8vJyVRmqpy1mzpyJ0tLSettDQ0ORnp6uNpaIiMhmaPlHsJopiqeffhoTJkxQvE/nzp3h7+9vsecSAFRVVaGoqAj+/v6Kj78x+tG1a1fcfvvt8PLywqZNm/Dggw82qI9AI4qHQYMGKba7uLggOjpabSwREdH/eb6+vvD19bV6v6ioKFy+fBlZWVmIiIgAAOzYsQMmkwmRkZENfr4bZ4TUXJNhjerioanoy65IZ5g0WKipt5d/S9p5aHONDtNl5fN1G+KUyVk6w/NapXSGr6u7dAYAnCyU/5x4uThJZxSVy3/WBnTrIJ0BAKai89bvZIXeIP+eiMoK6QwAqCgskA/RK29U11wZ17zqXvGu1uHCy9IZRVflX0+/CvnN/JzaB0tnEBAeHo4RI0YgMTERK1asQGVlJZKSkhAXF2c+0+LcuXMYOnQoPvroI/Tv3x85OTnYsGEDhg0bBl9fX/z+++9YsGABnJ2dMWrUKFXPr/k+D0RERDc7k9DuaCpr1qxBWFgYhg4dilGjRmHgwIFYuXKlub2yshJHjx5FWVkZAMDJyQnfffcdRo0ahdDQUDzwwANwc3PDDz/8UGvxpTU2M/JARERkK26Ghf/e3t5Yu3Ztve3BwcEWryMwMBBfffWVJs/N4oGIiKgGXhhLGactiIiISBWOPBAREdVwM0xbtCTNRh46d+6M48ePaxVHRERENkr1yMNbb71V5+1nzpzBqlWrzJtTPPXUU3I9IyIiIpukuniYPn062rdvD/sa+yGYTCZ89NFHcHBwgE6nY/FAREQ3Lc5aKFNdPEyePBl79+7F2rVrER4ebr7dwcEB3377Lbp3765pB4mIiJobz7ZQpnrNw4oVKzBnzhwMHz4cy5Yta9STGo1GlJSUWBxqt8YkIiKiltGoBZP33nsvMjIysGnTJowcOdLq5T9rquvypEveblwhQkREpLUb13zQ4miNGn22Rfv27bFt2zYMHjwYffr0UfUG1XV50hlPJjW2K0RERJoSQrujNZLa50Gn0yElJQXDhg3D7t27ERAQ0KDH1XV5UlOp/AWPiIiIqOlpss9DREQEpk2bBi8vL5w9exaTJk3SIpaIiIhskObbUxcVFWH16tVaxxIRETUbkxCaHa2R6mmLzZs3K7bn5OQ0ujNERES2QKB1/tLXiuriITY2FjqdTnGBpE6nk+oUERER2S7V0xYBAQHYuHEjTCZTnUd2dnZT9JOIiKjZmIR2R2ukuniIiIhAVlZWve3WRiWIiIhsHfd5UKZ62mLmzJkoLS2ttz00NBTp6elSnSIiIiLbpbp4GDRokGK7i4sLoqOjG90hIiIism1Sm0RpqaKwQDpD7+AgneHg5Sudcc1UJZ0BAAYHR+kMPycX6QxjVbV0RrVGm4CZhJ10hrFK/r9PB2936QwUnZfPAFDh3lY640j+JemM7j5+0hkAcKZc/gzyjqYK6YyrR36SzjjVsY90BgDcEij/3/hyabl0hpN7J+kMo8kkndEcWut0g1Y03+eBiIiIWjebGXkgIiKyFa31LAmtsHggIiKqgdMWyjhtQURERKpw5IGIiKgGjjwoky4ehBDYuXMnTpw4gYCAAAwfPhwOGpz1QERERLZJdfEwatQorFu3Dh4eHigqKsKoUaOQmZkJHx8fXLx4Ed26dcOuXbvg6yt/yiMREVFL4IJJZarXPKSlpcFoNAIAXnjhBVy5cgW//fYbzp8/j9OnT8PFxQVz5szRvKNERERkG6QWTO7YsQOpqakICQkBAHTo0AELFy7EN998o0nniIiIWgKvbaGsUWseblxy+9KlS+jSpYtFW2hoKHJzcxUfbzQazaMX5tsqKmBwlN9RkYiISJaplf7S10qjRh4mTJiA++67D5WVlTh58qRFW35+Pjw9PRUfn5qaCg8PD4vjrX+uakxXiIiIqJmpHnkYP368+f+PGTMGZWVlFu2fffYZevfurZiRkpKC5ORki9uKjx9S2xUiIqImwXEHZaqLh1WrlEcI5s6dCzs75YsXGQwGGAwGi9vKOWVBRER0U9B8h8mioiI8/vjjWscSERGRjWiS4mH16tVaxxIRETUbnm2hTPW0xebNmxXbc3JyGt0ZIiIiW8CzLZSpLh5iY2Oh0+kUq6kbp3ISERFR66N62iIgIAAbN26EyWSq88jOzm6KfhIRETUbIbQ7WiPVxUNERASysrLqbbc2KkFERGTruOZBmeppi5kzZ6K0tLTe9tDQUKSnp0t1ioiIiGyX6uJh0KBBiu0uLi6Ijo5udIeIiIjItjXq2hZNQVRXSmfo2rhIZ1RdLZbO8PAJkM4AgCvX5Beeniy4JJ0R6OUmnXGuykE6AwA6e8jn5JZVS2dcuWa0ficrvD28pDMAwHT+d+kMX/d20hnV1y5LZwBAgLe/dEZxeYV0htstt0pnBBrk/+1oZe+Jc9IZf7mtm3RGqVH+u7458GwLZTZTPBAREdmK1rpWQSuabxJFRERETa+oqAjx8fFwd3eHp6cnHnnkEVy9erVBjxVCYOTIkdDpdPj8889VPzeLByIiohpMQrujqcTHx+PgwYPYunUrvvzyS+zatQuTJ09u0GOXLl0qtScTpy2IiIhqsPVpi8OHDyMtLQ379u1D3759AQBvv/02Ro0ahUWLFiEwMLDex/7000/4+9//jv379yMgoHFr9DjyQERE1ISMRiNKSkosDqNRbtF1RkYGPD09zYUDAMTExECv12Pv3r31Pq6srAwPPfQQ3nnnHfj7N35xsuri4ffff0dhYaH55++++w7x8fEYNGgQHn74YWRkZDS6M0RERK1NamoqPDw8LI7U1FSpzPz8fLRrZ3mWlL29Pby9vZGfn1/v42bMmIEBAwZgzJgxUs+vuni4//77sWfPHgDAF198gSFDhuDq1au44447UFZWhujoaHz55ZdSnSIiImpJWu4wmZKSguLiYosjJSWlzuedPXs2dDqd4nHkyJFGvabNmzdjx44dWLp0qcQ7c53qNQ8HDx7En/70JwDXq6nXXnsNs2bNMrcvW7YMc+bMwV/+8hfpzhEREd3sDAYDDAZDg+779NNPY8KECYr36dy5M/z9/XH+/HmL26uqqlBUVFTvdMSOHTvw22+/wdPT0+L2+++/H4MGDcLOnTsb1EegEcWDvb09rly5AgA4efIkRo4cadE+cuRIi2KCiIjoZtOUZ0ko8fX1ha+vr9X7RUVF4fLly8jKykJERASA68WByWRCZGRknY+ZPXs2Hn30UYvbevbsiSVLlmD06NGq+ql62iI6Ohrr1q0DAPTp06dWpZKeno727dsrZtS5eKRCfkc4IiIiLQgN/9cUwsPDMWLECCQmJiIzMxPff/89kpKSEBcXZz7T4ty5cwgLC0NmZiYAwN/fHz169LA4AKBTp04ICQlR9fyqRx4WLFiAQYMGITc3FwMHDsTzzz+Pffv2ITw8HEePHsWGDRuwYsUKxYzU1FTMmzfP4ranH3sEM6ckqu0OERGR5mz9VE0AWLNmDZKSkjB06FDo9Xrcf//9eOutt8ztlZWVOHr0KMrKyjR/btXFQ3h4OPbu3YsXXngBr7/+OkpLS7FmzRrY29ujX79+WL9+PWJjYxUzUlJSkJycbHHb5SM/q+0KERHR/1ne3t5Yu3Ztve3BwcFWi6DGFkmN2iSqS5cuWLduHYQQOH/+PEwmE3x8fODg0LCLFtW1eOSao2NjukJERETNTGqTKJ1OBz8/PwQEBJgLh7Nnz2LSpEmadI6IiKgl3AzbU7ckzXeYLCoqwurVq7WOJSIiIhuhetpi8+bNiu05OTmN7gwREZEtuBkWTLYk1cVDbGwsdDqd4hsrc6UuIiKilmZi8aBI9bRFQEAANm7cCJPJVOeRnZ3dFP0kIiIiG6G6eIiIiEBWVla97dZGJYiIiGydENodrZHqaYuZM2eitLS03vbQ0FCkp6dLdYqIiIhsl+riYdCgQYrtLi4uiI6ObnSHiIiIyMaJm0B5ebmYO3euKC8vb/Gc1pRhS32xlQxb6outZNhSX2wlw5b6YisZttYXalo3RfFQXFwsAIji4uIWz2lNGbbUF1vJsKW+2EqGLfXFVjJsqS+2kmFrfaGmpfkmUURERNS6sXggIiIiVVg8EBERkSo3RfFgMBgwd+7cWlfibImc1pRhS32xlQxb6outZNhSX2wlw5b6YisZttYXalo6IVrrFhZERETUFG6KkQciIiKyHSweiIiISBUWD0RERKQKi4ebGJerEBFRS1B9bYvmUFhYiA8++AAZGRnIz88HAPj7+2PAgAGYMGECfH19W7iHtsFgMODnn39GeHh4S3flppWXl4fly5dj9+7dyMvLg16vR+fOnREbG4sJEybAzs6upbtIRGRzbO5si3379mH48OFo06YNYmJi4OfnBwAoKCjA9u3bUVZWhm+++QZ9+/aVep6zZ89i7ty5+OCDDxTvd+3aNWRlZcHb2xvdu3e3aCsvL8cnn3yChIQExYzDhw9jz549iIqKQlhYGI4cOYI333wTRqMRDz/8MO666y7FxycnJ9d5+5tvvomHH34Ybdu2BQAsXrxYMaem0tJSfPLJJzhx4gQCAgLw4IMPmrPqk52dDS8vL4SEhAAAPv74Y6xYsQJnzpxBUFAQkpKSEBcXp5jx5JNPYty4cVYvsmbNsmXLkJmZiVGjRiEuLg4ff/wxUlNTYTKZcN999+Hll1+GvX399fH+/fsRExOD0NBQODs7IyMjAw899BAqKirwzTffoHv37khLS4Obm5tUP4lsUWZmZq0/0KKiotC/f39N8i9duoQtW7ZY/X4EAJPJBL2+9kC4yWTC77//jk6dOmnSJ9JQi26OXYfIyEgxefJkYTKZarWZTCYxefJkcfvtt0s/z08//ST0er3ifY4ePSqCgoKETqcTer1eDB48WOTm5prb8/PzrWZ8/fXXwtHRUXh7ewsnJyfx9ddfC19fXxETEyPuuusuYWdnJ7Zv366YodPpRO/evcWQIUMsDp1OJ/r16yeGDBki7rzzTquvOTw8XFy8eFEIIcSZM2dEcHCw8PDwEP369RPe3t6iXbt2IicnRzHj1ltvFVu3bhVCCPHee+8JZ2dn8dRTT4nly5eL6dOnC1dXV/H+++9bfT16vV507dpVLFiwQOTl5Vnte03z588Xbm5u4v777xf+/v5iwYIFom3btuKVV14Rr732mvD19RVz5sxRzLjjjjvESy+9ZP75448/FpGRkUIIIYqKikTv3r3FU0891aD+GI1GsWHDBjF9+nQRFxcn4uLixPTp08Unn3wijEaj6tdXl/z8fDFv3rwG3ffs2bPiypUrtW6vqKgQ//3vf60+vrCwUOzYscP8eblw4YJYsGCBmDdvnjh06JC6jv9BSEiIOHbsWKMfbzKZxI4dO8TKlSvFli1bREVFhdXHnD17Vly4cMH8865du8RDDz0kBg4cKOLj48UPP/xgNWPRokXi1KlTje73DVu2bBEvvvii2L17txBCiO3bt4uRI0eK4cOHi3/84x8NzikrKxPvv/++mDhxohgxYoQYNWqUSEpKEtu2bbP62IKCAjFw4ECh0+lEUFCQ6N+/v+jfv7/5u27gwIGioKCg0a/xhoZ8xxYXF4uxY8cKJycn0a5dO/Hiiy+Kqqoqc3tDvmOpZdhc8eDk5CQOHz5cb/vhw4eFk5OT1ZwvvvhC8ViyZInVD2VsbKy4++67xYULF8Tx48fF3XffLUJCQsTp06eFEA37YEdFRYnnn39eCCHEunXrhJeXl3juuefM7bNnzxZ//vOfFTNSU1NFSEhIrSLD3t5eHDx4UPGxf6TT6cxfCvHx8WLAgAHi8uXLQgghrly5ImJiYsSDDz6omOHs7Gz+Eu3Tp49YuXKlRfuaNWtE9+7drfZj27ZtYtq0acLHx0c4ODiIe+65R2zZskVUV1c36LV06dJFfPbZZ0KI619SdnZ24l//+pe5fePGjSI0NNTqa/ntt9/MP1dXVwsHBweRn58vhBDi22+/FYGBgVb7cvz4cdG5c2fh5OQkoqOjxbhx48S4ceNEdHS0cHJyEqGhoeL48eMNel1KGvJlnJubK/r16yf0er2ws7MTf/vb3yyKiIZ8Zvfu3Ss8PDyETqcTXl5eYv/+/SIkJER07dpVdOnSRTg7O4usrCzFjDfffLPOw87OTqSkpJh/tmbkyJHmz+jFixdFZGSk0Ol0wtfXV+j1ehEWFibOnz+vmNG/f3+xZcsWIYQQn3/+udDr9eKee+4Rs2bNEvfee69wcHAwt9dHp9MJOzs7ERMTI9avX9+ognDFihXC3t5eRERECHd3d/Hxxx8LNzc38eijj4rHHntMODs7i6VLl1rNOX78uAgKChLt2rUTHTt2FDqdTtx9990iMjJS2NnZibFjx4rKysp6H3///feLqKgoceTIkVptR44cEQMGDBB//etfrfajuLhY8fjuu++sftaeeuop0a1bN/Hpp5+K9957TwQFBYm7777b/P7m5+cLnU5ntS/U/GyueAgODharV6+ut3316tUiKCjIas6Nv251Ol29h7UPdrt27cSBAwfMP5tMJjFlyhTRqVMn8dtvvzXoi9jd3d38i6O6ulrY29uL7Oxsc/svv/wi/Pz8rL6ezMxM0a1bN/H000+b/9qSKR46d+4svv32W4v277//XnTs2FExo23btmL//v1CiOvvz08//WTRfuLECeHs7NzgflRUVIgNGzaI4cOHCzs7OxEYGCiee+45q79snZ2dzUWcEEI4ODiIX3/91fzzqVOnRJs2bRQzgoKCzH8BCnH9F69OpxNlZWVCCCFOnjzZoEI1JiZGjBkzps6rABYXF4sxY8aIYcOGWc35+eefFY8NGzZY/bwlJCSIyMhIsW/fPrF161YREREh+vbtK4qKioQQDfsyjomJEY8++qgoKSkRb7zxhujQoYN49NFHze0TJ04UsbGxihk6nU506NBBBAcHWxw6nU60b99eBAcHi5CQEKvvyR8/K1OnThXdu3c3j46dPXtWREREiClTpihmuLi4mB8TGRkpFixYYNH+9ttviz59+ljtx6pVq8SYMWOEg4ODaNu2rZg2bZr45ZdfrL6GG7p3724utnfs2CGcnJzEO++8Y25ftWqVCA8Pt5ozcuRI8dhjj5lHZxcsWCBGjhwphBDi2LFjIjg4WMydO7fex7u6ulp8B9W0f/9+4erqarUfN75D6zsa8h3bqVMnkZ6ebv75woULon///mLYsGGivLycIw82zOaKh2XLlgmDwSCeeuop8cUXX4g9e/aIPXv2iC+++EI89dRTwtnZ2eIfXH0CAwPF559/Xm/7jz/+aPVD6ebmVucQ7RNPPCE6dOggdu3a1aDi4cSJE+afXV1dLf7aPXXqVIN+QQlxfXQgISFB3HrrreKXX34RDg4OqouHG3+lBQYG1vria0hfHn74YfHII48IIYQYO3aseOGFFyzaX3vtNdGzZ0+r/ahrWPT06dNi7ty5IigoyOr7GhISIr7++mshxPUvTL1eLz755BNz+3/+8x8RHBysmDFt2jTRo0cP8fXXX4sdO3aIO++8UwwZMsTcnpaWJrp06aKYIcT1Qkbpl8iBAwesFlRCKBe8Df0yDgwMFHv37jX/XF5eLkaPHi169+4tLl682KAvYy8vL/PnvqKiQuj1eovMrKws0b59e8WMxx57TPTu3bvWvx+ZgveWW24RX3zxhUX7tm3brBYhHh4e4ueffxZCXC94b/z/G06cOGG10PxjPwoKCsTChQtFWFiY0Ov1ol+/fmLlypWipKREMaOugvePn5uTJ09a7YcQQrRp08Zi6sdoNAoHBwdRWFgohLg+uqL02W/btq3YuXNnve3p6emibdu2Vvvh7u4uFi5cKHbu3Fnn8d5771n9rDk7O9eaKi0pKRFRUVHirrvuEjk5OSwebJTNFQ9CCLF+/XoRGRkp7O3tzV+e9vb2IjIyUmzYsKFBGaNHjxYvvvhive0//fST1b/A+vXrJz766KM625544gnh6elp9YN96623mn/JCXF9pOGPQ4q7du1q0F9gf7Ru3Trh5+cn9Hq96i/inj17ij59+ghXV1fx73//26L9v//9r9VfCufOnRPBwcFi8ODBIjk5WTg7O4uBAweKxMREMXjwYOHo6Cj+85//WO2H0pyqyWSqNSpS0wsvvCB8fX3Fo48+KkJCQsTs2bNFp06dxPLly8WKFStEx44dxYwZMxQzrly5IsaNG2f+nA0YMMDii+ybb76xKEjqExAQoDjsvXnzZhEQEGA1p23btuL9998Xp06dqvP4z3/+Y/Xz5uLiUmtNQWVlpYiNjRW33nqrOHDgQIMyTp48af65ZsF7+vTpBhW8GzduFB07dhRvv/22+bbGFA83Ct527dpZjC4Jcb3gNRgMihn33HOPmD17thBCiOHDh9eaLnnvvfdE165drfajrs/srl27xPjx44WLi4twcXFRzLjxB4cQ1/8d6XQ6i38rO3fuFB06dFDMEOJ6gfjHaaNLly4JnU5nLl5ycnIU35PHH39cBAUFiY0bN1qMlhUXF4uNGzeK4OBgkZSUZLUfQ4YMEQsXLqy3vSHfsbfcckud3xdXrlwRUVFRolevXiwebJRNFg83VFRUiNzcXJGbm9ughVF/tGvXLotf2jVdvXpVsfoW4vpf0TeGA+sydepUq/84li9fLr788st621NSUsx/yatx9uxZ8fnnn4urV682+DEvvfSSxZGWlmbR/swzz4i4uDirOZcuXRKzZs0S3bt3F05OTsLR0VEEBQWJhx56SOzbt8/q44ODg81/JTVWdXW1ePXVV8Vf/vIX8dprrwmTySTWrVsnOnbsKNq2bSsmTJjQ4Pfm2rVrdS4ubKgXX3xReHl5icWLF4uff/5Z5Ofni/z8fPHzzz+LxYsXC29vb8Vh5BuGDRsm5s+fX297Q76Me/bsWasoFOJ/BUSnTp2sfhmHhYVZrK/58ssvzVM5QgixZ8+eBv2SE0KI33//Xdx1111ixIgRIi8vr1HFw6hRo8S9994rvLy8ahVpe/bssTrtd+jQIdG2bVuRkJAg5s+fL1xdXcXDDz8sXn31VZGQkCAMBoNYtWqVYoZer1cseIuLi2ut/6npiSeeEF27dhWvvPKK6N+/vxg/frwICwsTX3/9tUhLSxM9e/YUkyZNUswQQojx48eL6OhocfjwYZGTkyMeeOABi2mXnTt3Kk4/lpeXiylTpghHR0eh1+uFk5OTcHJyEnq9Xjg6OoqpU6eK8vJyq/1YuXKl4rqV/Px8iwXJdXnyySfrXV9RUlIiIiMjWTzYKJsuHohuFgsWLBABAQEW88A6nU4EBAQo/nX2Rxs3bhQff/xxve1FRUXiww8/VMx49tln611fUVlZKe655x6rBchLL70k1q1bV2/7c889J+677z7FjD8ymUzitddeE/7+/sLOzk5V8TBhwgSLo+bI48yZM8Xw4cOt5pw4cULExcUJNzc382img4ODGDBggNi0aZPVx1sbLWuIq1evisTERNGjRw8xefJkYTQaxRtvvCEcHR2FTqcTQ4YMadBzFBQUiNtvv938WQsKCrJYw/Dpp5+Kt956y2pOcXGx2LFjh1i7dq1Yu3at2LFjR53rdppSUVFRrdGkPyopKbH6Rx61DJvb54HoZnby5EmL8+Zv7IfRXKqqqlBWVgZ3d/d628+dO4egoKBGP0dZWRns7OxUXzI5KysLu3fvRkJCAry8vBr9/H9UWloKOzs7ODk5Nej+QgicP38eJpMJPj4+cHBw0KQfMsrLy1FZWal6P5Hjx4/DaDQiLCxMcT8ToqbA7amJNBQSEoKoqChERUWZC4ezZ89i0qRJ0tkNybG3t6+3cACu76g5b948qX5cvHgRU6dOVf24iIgITJs2DV5eXpq9J0VFRXj88ccbfH+dTgc/Pz8EBASYCwct+iKT4eTkBDc3N9UZXbt2RY8ePWoVDg3JuXbtGnbv3o1Dhw7VaisvL8dHH33UoD5okaNVX6iZtfDIB1Gr15D9GZorpzVl2FJfbCWjITl1bX537tw5c3tDT4/UYhM9LTKoZXCsi0jS5s2bFdtzcnKaLac1ZdhSX2wlQ4ucWbNmoUePHti/fz8uX76M6dOnY+DAgdi5c6eqbaDryrnjjjtU5WiRQS2Dax6IJOn1euh0OsWrnOp0OlRXVzd5TmvKsKW+2EqGFjl+fn7Ytm0bevbsCeD6OpDHH38cX331FdLT0+Hi4oLAwECr/dAiR6u+UPPjmgciSQEBAdi4cSNMJlOdR3Z2drPltKYMW+qLrWRokXPt2jWLdRI6nQ7Lly/H6NGjER0djWPHjjWoH1rkaNUXan4sHogkRUREICsrq952a38lapnTmjJsqS+2kqFFTlhYGPbv31/r9mXLlmHMmDG45557rPZBqxyt+kItoNlWVxC1UlpsSKZVTmvKsKW+2EqGFjlabH6nVY5WfaHmxzUPREREpAqnLYiIiEgVFg9ERESkCosHIiIiUoXFAxEREanC4oGIiIhUYfFAREREqrB4ICIiIlVYPBAREZEq/w+myKcf8h0oNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "heatmap((C_infty[0]-  C_infty2[0]) / C_infty[0], center = 0, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0a762a0a-5bc4-4534-9b35-36cf2b17cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_grad = mx.grad.detach().clone()\n",
    "my_grad = my.grad.detach().clone()\n",
    "C_grad = C.grad.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5ea917bf-2060-49cc-a74d-a1be7f46472e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -4.3255,  -8.3788,   8.8664,  -9.1317,  -8.6410, -11.0822,  -5.8388,\n",
       "          5.5822,  10.1769,   4.7544,   0.4675,  10.0877,  -9.7420, -10.1103,\n",
       "          6.4100,   4.1171,  16.7880])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_grad[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c5f0e0f9-13f7-4bdc-9ba9-835209c9c726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6936, -7.0199, -7.0199, -7.0199, -7.0199, -7.0199, -7.0199, -7.0199,\n",
       "        36.7321, -7.0199, -7.0199, 35.0043, -7.0199, -7.0199, -7.0199, 18.8289,\n",
       "        -7.0199])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_new_grad[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "43eaff02-e476-4c9a-b7b3-138857aee7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mx[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3cdd1c65-9db6-4b6d-af2b-941c972b72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = my[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9b8d8d8b-017a-4f0c-8186-18aea0000a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dense = mx_dense[0, 0]\n",
    "b_dense = my_dense[0, 0]\n",
    "C_test = C_dense[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5e384efa-3b3a-41bb-9fac-19d508a74a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1836, grad_fn=<SinkhornBackward>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(a, b, C[0], epsilon=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7c1a284b-d0d7-44c5-82e7-57569457a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1836)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(a_dense, b_dense, C_test, epsilon=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a372495b-3fd1-412c-98ca-ee5c025b44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test, g_test, lP_test = sinkhorn_internal(a, b, C[0], epsilon=.1)\n",
    "f_test2, g_test2, lP_test2 = sinkhorn_internal(a_dense, b_dense, C_test, epsilon=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "299e08fd-e7ff-4b48-bdeb-d3ec97cc53af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6038,  0.6738,  1.3214, -0.6177,  0.5780,  0.0400, -0.5445,  1.1845,\n",
       "         1.2837, -0.3121,  0.1945,  0.7306, -1.2066,  0.6633,  1.4521, -0.2891,\n",
       "         1.5098], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "37b77704-d544-444d-9c64-ef79baa68b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test2_z = f_test2.clone()\n",
    "f_test2_z[mx_mask[0, 0] == 0] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4bb11112-9964-48be-9451-a3207d0ed4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6497,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         1.3296,  0.0000,  0.0000,  0.7765,  0.0000,  0.0000,  0.0000, -0.2433,\n",
       "         0.0000])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(f_test).index_add(0, mx_index[0, 0], f_test2_z )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a9ec6776-0bcd-47c1-bb2b-aa9c1d57ed03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  8, 11, 15,  0])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_index[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b26bb9f8-a658-43b1-b3ed-0f2c87ea7eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6497,  1.3296,  0.7765, -0.2433, -0.5727])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a347a4-c8a9-47a0-aabc-df42aae86f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
